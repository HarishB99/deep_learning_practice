{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "asm_files_dir = './dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asm_files = os.listdir(asm_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_data_seg(line):\n",
    "    match = re.search('^\\.[a-z]{0,1}data', line)\n",
    "    match_found = False\n",
    "    try:\n",
    "        found = match.group(0)\n",
    "        match_found = True\n",
    "    except AttributeError:\n",
    "        match_found = False\n",
    "    finally:\n",
    "        return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_text_seg(line):\n",
    "    match = re.search('^\\.text', line)\n",
    "    match_found = False\n",
    "    try:\n",
    "        found = match.group(0)\n",
    "        match_found = True\n",
    "    except AttributeError:\n",
    "        match_found = False\n",
    "    finally:\n",
    "        return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_2digit_hex(text):\n",
    "    match = re.match('^[0-9A-F]{2}\\+?$', text)\n",
    "    match_found = False\n",
    "    try:\n",
    "        found = match.group(0)\n",
    "        match_found = True\n",
    "    except AttributeError:\n",
    "        match_found = False\n",
    "    finally:\n",
    "        return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_text_comment(text):\n",
    "    match = re.match('^_[a-z]?text$', text)\n",
    "    match_found = False\n",
    "    try:\n",
    "        found = match.group(0)\n",
    "        match_found = True\n",
    "    except AttributeError:\n",
    "        match_found = False\n",
    "    finally:\n",
    "        return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_data_comment(text):\n",
    "    match = re.match('^_[a-z]?data$', text)\n",
    "    match_found = False\n",
    "    try:\n",
    "        found = match.group(0)\n",
    "        match_found = True\n",
    "    except AttributeError:\n",
    "        match_found = False\n",
    "    finally:\n",
    "        return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_addr_label(text):\n",
    "    return True if re.match('^sub_[0-9A-F]{6}\\:?$', text) or re.match('^loc_[0-9A-F]{6}\\:?$', text) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    with open(file, 'r', encoding='ISO-8859-1') as f:\n",
    "        struct_dict = {\n",
    "            \"text_arr\": [],\n",
    "            \"data_arr\": [],\n",
    "            \"file_name\": file\n",
    "        }\n",
    "        for asm_line in f:\n",
    "            asm_line = asm_line.strip()\n",
    "            if is_text_seg(asm_line):\n",
    "                struct_dict[\"text_arr\"].append(asm_line)\n",
    "            elif is_data_seg(asm_line):\n",
    "                struct_dict[\"data_arr\"].append(asm_line)\n",
    "            else:\n",
    "                continue\n",
    "        return struct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_of_comment(arr):\n",
    "    indices = [ i for i, token in enumerate(arr) if token.startswith(';') ]\n",
    "    if len(indices) > 0:\n",
    "        return indices[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_commas(line_arr):\n",
    "    newlinearr = []\n",
    "    for line in line_arr:\n",
    "        newline = []\n",
    "        for token in line:\n",
    "            if ',' in token:\n",
    "                temp = token.split(',')\n",
    "                temp = [ item for item in temp if item != '' ]\n",
    "                for item in temp:\n",
    "                    newline.append(item)\n",
    "            else:\n",
    "                newline.append(token)\n",
    "        newlinearr.append(newline)\n",
    "    return newlinearr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_lines(line_arr, segment):\n",
    "    # Split by whitespace each line in line_arr\n",
    "    line_arr = [ line.split() for line in line_arr ]\n",
    "    # Remove all comments from each line (array)\n",
    "    line_arr = [ line[:(start_of_comment(line))] for line in line_arr ]\n",
    "    # Remove the first word (\".text*\" or \".*data*\") \n",
    "    # from each line (array), depending on whether \n",
    "    # they are data segment or text segment\n",
    "    if segment == 'text':\n",
    "        line_arr = [ [token for token in line if not is_text_seg(token)] for line in line_arr ]\n",
    "    else:\n",
    "        line_arr = [ [token for token in line if not is_data_seg(token)] for line in line_arr ]\n",
    "    # Remove hexadecimal numbers (purpose is to \n",
    "    # remove the first few hex numbers which probably \n",
    "    # is the hex representation of the opcodes)\n",
    "    line_arr = [ [token for token in line if not is_2digit_hex(token)] for line in line_arr ]\n",
    "    # Remove all '??' from line\n",
    "    line_arr = [ [token for token in line if not ('??' in token) ] for line in line_arr ]\n",
    "    # Split all tokens using ','\n",
    "    line_arr = remove_commas(line_arr)\n",
    "    # Remove all empty line (array).\n",
    "    line_arr = [ line for line in line_arr if line != [] ]\n",
    "    return line_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_symbols(symbol, line):\n",
    "    newline = []\n",
    "    for i, token in enumerate(line):\n",
    "        if symbol in token:\n",
    "            temp_arr = token.split(symbol)\n",
    "            for j in range(1, len(temp_arr), 2):\n",
    "                temp_arr.insert(j, symbol)\n",
    "            temp_arr = [ val for val in temp_arr if val ]\n",
    "            for val in temp_arr:\n",
    "                newline.append(val)\n",
    "        else:\n",
    "            newline.append(token)\n",
    "    return newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(line_arr, keywords_dict):\n",
    "    processed_line_arr = [ line for line in line_arr if (not (is_text_comment(line[0]) or is_data_comment(line[0]))) ]\n",
    "    processed_line_arr = [ line for line in processed_line_arr if (not (line[0].startswith('assume'))) ]\n",
    "    processed_line_arr = [ ['addr' if is_addr_label(token) else token for token in line] for line in processed_line_arr ]\n",
    "    processed_line_arr = [ line for line in processed_line_arr if not (re.match('^var_[0-9A-F]{1,2}$', line[0])) ]\n",
    "    processed_line_arr = [ separate_symbols('[', line) for line in processed_line_arr ]\n",
    "    processed_line_arr = [ separate_symbols(']', line) for line in processed_line_arr ]\n",
    "    processed_line_arr = [ separate_symbols('+', line) for line in processed_line_arr ]\n",
    "    processed_line_arr = [ separate_symbols('-', line) for line in processed_line_arr ]\n",
    "    processed_line_arr = [ [keywords_dict.get(token, token) for token in line] for line in processed_line_arr ]  # In production, change 'keywords_dict.get(token, token)' to 'keywords_dict.get(token, None)' and remove all 'false'y values thereafter\n",
    "    processed_line_arr = [ [token for token in line if token] for line in processed_line_arr ]\n",
    "    return processed_line_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extra_processing(line_arr):  # If approved, then add this to process_dataset\n",
    "#     processed_line_arr1 = []\n",
    "#     for i, line in enumerate(line_arr):\n",
    "#         if len(line) < 1:\n",
    "#             print(i, ': ', line)\n",
    "#         elif not (is_text_comment(line[0]) or is_data_comment(line[0])):\n",
    "#             processed_line_arr1.append(line)\n",
    "    \n",
    "#     processed_line_arr2 = []\n",
    "#     for i, line in enumerate(processed_line_arr1):\n",
    "#         if len(line) < 1:\n",
    "#             print(i, ': ', line)\n",
    "#         elif not (line[0].startswith('assume')):\n",
    "#             processed_line_arr2.append(line)\n",
    "    \n",
    "#     processed_line_arr = []\n",
    "#     for i, line in enumerate(processed_line_arr2):\n",
    "#         if len(line) < 1:\n",
    "#             print(i, ': ', line)\n",
    "#         elif not (line[0].endswith(':')):\n",
    "#             processed_line_arr.append(line)\n",
    "#     processed_line_arr = [ line for line in line_arr if (not (is_text_comment(line[0]) or is_data_comment(line[0]))) ]\n",
    "#     processed_line_arr = [ line for line in processed_line_arr if (not (line[0].startswith('assume'))) ]\n",
    "#     processed_line_arr = [ line for line in processed_line_arr if (not (line[0].endswith(':'))) ]\n",
    "#     processed_line_arr = [ line for line in line_arr if (not (is_text_comment(line[0]) or is_data_comment(line[0]))) ]\n",
    "#     processed_line_arr = [ line for line in processed_line_arr if (not (line[0].startswith('assume'))) ]\n",
    "#     processed_line_arr = [ ['addr' if is_addr_label(token) else token for token in line] for line in processed_line_arr ]\n",
    "#     processed_line_arr = [ line for line in processed_line_arr if not (re.match('^var_[0-9A-F]{1,2}$', line[0])) ]\n",
    "#     return processed_line_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arr = [struct_dict for struct_dict in map(lambda x: read_file(os.path.join(asm_files_dir, x)), asm_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arr_2 = [{ \n",
    "    \"text_arr\": cleanse_lines(struct_dict[\"text_arr\"], 'text'), \n",
    "    \"data_arr\": cleanse_lines(struct_dict[\"data_arr\"], 'data'), \n",
    "    \"file_name\": struct_dict[\"file_name\"] \n",
    "} for struct_dict in dataset_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./keywordsdict.txt', 'r') as f:\n",
    "    keywords_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arr_3 = [{ \n",
    "    \"text_arr\": process_dataset(struct_dict[\"text_arr\"], keywords_dict), \n",
    "    \"data_arr\": process_dataset(struct_dict[\"data_arr\"], keywords_dict), \n",
    "    \"file_name\": struct_dict[\"file_name\"] \n",
    "} for struct_dict in dataset_arr_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/01kcPWA9K2BOxQeS5Rju.asm'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_arr_3[0][\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sub_10001000', 'proc', 'near'],\n",
       " ['arg_0', '=', 'dword', 'ptr', '4'],\n",
       " ['arg_4', '=', 'dword', 'ptr', '8'],\n",
       " ['arg_8', '=', 'dword', 'ptr', '0Ch'],\n",
       " [72, '0FFFFFFFFh'],\n",
       " [72, 'offset', 'SEH_10001000'],\n",
       " [73, 19, 'large', 'fs:0'],\n",
       " [72, 19],\n",
       " [73, 'large', 'fs:0', 24],\n",
       " [74, 24, '20h'],\n",
       " [73, 19, '[', 24, '+', '2Ch', 'arg_4', ']'],\n",
       " [72, 25],\n",
       " [72, 19],\n",
       " [83, 21, '[', 24, '+', '34h', 'var_28', ']'],\n",
       " [73, '[', 24, '+', '34h', 'var_2C', ']', '0'],\n",
       " [86],\n",
       " [73, 21, '[', 24, '+', '30h', 'arg_8', ']'],\n",
       " [72, 21],\n",
       " [73, 21, 19],\n",
       " [73, '[', 24, '+', '34h', 'var_4', ']', '1'],\n",
       " [86],\n",
       " [73, 25, '[', 24, '+', '30h', 'arg_0', ']'],\n",
       " [72, 19],\n",
       " [73, 21, 25],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '30h', 'var_28', ']'],\n",
       " [73, '[', 24, '+', '30h', 'var_2C', ']', '1'],\n",
       " [73, 'byte', 'ptr', '[', 24, '+', '30h', 'var_4', ']', '0'],\n",
       " [86],\n",
       " [73, 21, '[', 24, '+', '30h', 'var_C', ']'],\n",
       " [73, 19, 25],\n",
       " [109, 25],\n",
       " [73, 'large', 'fs:0', 21],\n",
       " [91, 24, '2Ch'],\n",
       " ['retn'],\n",
       " ['sub_10001000', 'endp'],\n",
       " ['align', '10h'],\n",
       " ['public', 'RunPhotoDownloader'],\n",
       " ['RunPhotoDownloader', 'proc', 'near'],\n",
       " ['hObject', '=', 'dword', 'ptr', '-', '32Ch'],\n",
       " ['hModule', '=', 'dword', 'ptr', '-', '328h'],\n",
       " ['Msg', '=', 'tagMSG', 'ptr', '-', '31Ch'],\n",
       " ['var_300', '=', 'dword', 'ptr', '-', '300h'],\n",
       " ['var_2FC', '=', 'dword', 'ptr', '-', '2FCh'],\n",
       " ['var_2E8', '=', 'byte', 'ptr', '-', '2E8h'],\n",
       " ['var_2E4', '=', 'byte', 'ptr', '-', '2E4h'],\n",
       " ['var_2E0', '=', 'byte', 'ptr', '-', '2E0h'],\n",
       " ['var_2C0', '=', 'dword', 'ptr', '-', '2C0h'],\n",
       " ['var_298', '=', 'byte', 'ptr', '-', '298h'],\n",
       " ['lpAddress', '=', 'dword', 'ptr', '-', '27Ch'],\n",
       " ['var_278', '=', 'byte', 'ptr', '-', '278h'],\n",
       " ['var_274', '=', 'byte', 'ptr', '-', '274h'],\n",
       " ['var_270', '=', 'dword', 'ptr', '-', '270h'],\n",
       " ['var_268', '=', 'dword', 'ptr', '-', '268h'],\n",
       " ['var_25C', '=', 'dword', 'ptr', '-', '25Ch'],\n",
       " ['Dest', '=', 'word', 'ptr', '-', '258h'],\n",
       " ['var_214', '=', 'byte', 'ptr', '-', '214h'],\n",
       " ['var_210', '=', 'byte', 'ptr', '-', '210h'],\n",
       " ['var_1CE', '=', 'byte', 'ptr', '-', '1CEh'],\n",
       " ['Value', '=', 'dword', 'ptr', '8'],\n",
       " ['flProtect', '=', 'dword', 'ptr', '0Ch'],\n",
       " ['arg_8', '=', 'dword', 'ptr', '10h'],\n",
       " [72, 23],\n",
       " [73, 23, 24],\n",
       " [105, 24, '0FFFFFFF8h'],\n",
       " [74, 24, '30Ch'],\n",
       " [73, 22, '[', 23, '+', 'Value', ']'],\n",
       " [96, 22, 22],\n",
       " [73, 19, '___security_cookie'],\n",
       " [72, 20],\n",
       " [72, 25],\n",
       " [73, '[', 24, '+', '314h', 'var_4', ']', 19],\n",
       " [72, 26],\n",
       " ['jz', 'loc_100012C1'],\n",
       " [73, 20, '[', 23, '+', 'flProtect', ']'],\n",
       " [96, 20, 20],\n",
       " ['jz', 'loc_100012C1'],\n",
       " [73, 21, '10h'],\n",
       " [73, 25, 'offset', 'aParamsForceTru'],\n",
       " [83, 26, '[', 24, '+', '318h', 'var_210', ']'],\n",
       " [84, 117],\n",
       " ['movsw'],\n",
       " [78, 19, 19],\n",
       " [73, 21, '71h'],\n",
       " [83, 26, '[', 24, '+', '318h', 'var_1CE', ']'],\n",
       " [84, 'stosd'],\n",
       " ['stosw'],\n",
       " [72, '10h'],\n",
       " [83, 19, '[', 24, '+', '31Ch', 'Dest', ']'],\n",
       " [72, 19],\n",
       " [72, 22],\n",
       " [86, 'ds:_ltow'],\n",
       " [91, 24, '0Ch'],\n",
       " [72, 20],\n",
       " [83, 21, '[', 24, '+', '31Ch', 'var_274', ']'],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '31Ch', 'var_25C', ']'],\n",
       " [72, 21],\n",
       " [83, 22, '[', 24, '+', '320h', 'var_214', ']'],\n",
       " [72, 22],\n",
       " [83, 19, '[', 24, '+', '324h', 'var_278', ']'],\n",
       " [72, 19],\n",
       " [83, 21, '[', 24, '+', '328h', 'var_2E0', ']'],\n",
       " [72, 21],\n",
       " [86, 'sub_10001000'],\n",
       " [91, 24, '0Ch'],\n",
       " [72, 19],\n",
       " [83, 22, '[', 24, '+', '324h', 'var_2FC', ']'],\n",
       " [72, 22],\n",
       " [86, 'sub_10001000'],\n",
       " [91, 24, '0Ch'],\n",
       " [72, 19],\n",
       " [83, 21, '[', 24, '+', '320h', 'var_278', ']'],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '320h', 'var_300', ']'],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '320h', 'var_2E4', ']'],\n",
       " [86],\n",
       " [73, 19, '[', 23, '+', 'arg_8', ']'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'short', 'loc_100011A1'],\n",
       " [72, 19],\n",
       " [72, 'offset', 'unk_100020AC'],\n",
       " [83, 19, '[', 24, '+', '328h', 'lpAddress', ']'],\n",
       " [72, 19],\n",
       " [83, 21, '[', 24, '+', '32Ch', 'var_300', ']'],\n",
       " [72, 21],\n",
       " [86, 'sub_10001000'],\n",
       " [91, 24, '0Ch'],\n",
       " [72, 19],\n",
       " [83, 22, '[', 24, '+', '328h', 'var_2E4', ']'],\n",
       " [72, 22],\n",
       " [86, 'sub_10001000'],\n",
       " [91, 24, '0Ch'],\n",
       " [72, 19],\n",
       " [83, 21, '[', 24, '+', '324h', 'lpAddress', ']'],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '324h', 'var_2E8', ']'],\n",
       " [86],\n",
       " [83, 21, '[', 24, '+', '324h', 'Msg.pt.y', ']'],\n",
       " [86],\n",
       " ['loc_100011A1:'],\n",
       " [73, 19, '[', 24, '+', '324h', 'var_268', ']'],\n",
       " [73, 25, '8'],\n",
       " [81, 19, 25],\n",
       " [73, 19, '[', 24, '+', '324h', 'lpAddress', ']'],\n",
       " ['jnb', 'short', 'loc_100011BF'],\n",
       " [83, 19, '[', 24, '+', '324h', 'lpAddress', ']'],\n",
       " ['loc_100011BF:'],\n",
       " [72, 19],\n",
       " [86, 'ds:VirtualAlloc'],\n",
       " [78, 19, 19],\n",
       " [73, 21, '11h'],\n",
       " [83, 26, '[', 24, '+', '318h', 'var_2C0', ']'],\n",
       " [84, 'stosd'],\n",
       " [73, '[', 24, '+', '318h', 'Msg.pt.x', ']', 19],\n",
       " [73, '[', 24, '+', '318h', 'Msg.pt.y', ']', 19],\n",
       " [73, '[', 24, '+', '318h', 'var_300', ']', 19],\n",
       " [73, '[', 24, '+', '318h', 'var_2FC', ']', 19],\n",
       " [81, '[', 24, '+', '318h', 'var_25C', ']', 25],\n",
       " [73, 19, '[', 24, '+', '318h', 'var_270', ']'],\n",
       " [73, '[', 24, '+', '318h', 'var_2C0', ']', '44h'],\n",
       " ['jnb', 'short', 'loc_10001202'],\n",
       " [83, 19, '[', 24, '+', '318h', 'var_270', ']'],\n",
       " ['loc_10001202:'],\n",
       " [83, 21, '[', 24, '+', '318h', 'Msg.pt', ']'],\n",
       " [72, 21],\n",
       " [83, 22, '[', 24, '+', '31Ch', 'var_2C0', ']'],\n",
       " [72, 22],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, 19],\n",
       " [72, '0'],\n",
       " [86, 'ds:LoadLibraryA'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'loc_100012B4'],\n",
       " [73, 19, '[', 24, '+', '33Ch', 'hModule', ']'],\n",
       " [73, 26, 'ds:GetProcAddress'],\n",
       " [72, '0'],\n",
       " [72, 19],\n",
       " [86, 26],\n",
       " [96, 19, 19],\n",
       " [98, 'short', 'loc_1000127E'],\n",
       " [73, 25, 'ds:GetMessageW'],\n",
       " [73, 20, 'ds:DispatchMessageW'],\n",
       " ['loc_10001248:'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [72, '0'],\n",
       " [83, 21, '[', 24, '+', '348h', 'Msg', ']'],\n",
       " [72, 21],\n",
       " [86, 25],\n",
       " [81, 19, '0FFFFFFFFh'],\n",
       " ['jz', 'short', 'loc_10001271'],\n",
       " [73, 19, '[', 24, '+', '33Ch', 'Msg.message', ']'],\n",
       " [81, 19, '2003h'],\n",
       " ['jz', 'short', 'loc_1000127E'],\n",
       " [81, 19, '0Fh'],\n",
       " ['jnz', 'short', 'loc_10001271'],\n",
       " [83, 22, '[', 24, '+', '33Ch', 'Msg', ']'],\n",
       " [72, 22],\n",
       " [86, 20],\n",
       " ['loc_10001271:'],\n",
       " [73, 19, '[', 24, '+', '33Ch', 'hModule', ']'],\n",
       " [72, '0'],\n",
       " [72, 19],\n",
       " [86, 26],\n",
       " [96, 19, 19],\n",
       " [114, 'short', 'loc_10001248'],\n",
       " ['loc_1000127E:'],\n",
       " [73, 21, '[', 24, '+', '33Ch', 'hObject', ']'],\n",
       " [73, 25, 'ds:CloseHandle'],\n",
       " [72, 21],\n",
       " [86, 25],\n",
       " [73, 22, '[', 24, '+', '33Ch', 'hModule', ']'],\n",
       " [72, 22],\n",
       " [86, 25],\n",
       " [83, 21, '[', 24, '+', '33Ch', 'var_298', ']'],\n",
       " [86],\n",
       " [73, 40, '1'],\n",
       " [73, 21, '[', 24, '+', '33Ch', 'var_28', ']'],\n",
       " [86, '@__security_check_cookie@4'],\n",
       " [109, 26],\n",
       " [109, 25],\n",
       " [109, 20],\n",
       " [73, 24, 23],\n",
       " [109, 23],\n",
       " ['retn'],\n",
       " ['loc_100012B4:'],\n",
       " [83, 21, '[', 24, '+', '33Ch', 'var_298', ']'],\n",
       " [86],\n",
       " ['loc_100012C1:'],\n",
       " [73, 21, '[', 24, '+', '33Ch', 'var_28', ']'],\n",
       " [78, 40, 40],\n",
       " [86, '@__security_check_cookie@4'],\n",
       " [109, 26],\n",
       " [109, 25],\n",
       " [109, 20],\n",
       " [73, 24, 23],\n",
       " [109, 23],\n",
       " ['retn'],\n",
       " ['RunPhotoDownloader', 'endp'],\n",
       " ['align', '10h'],\n",
       " ['sub_100012FD', 'proc', 'near'],\n",
       " [78, 19, 19],\n",
       " ['inc', 19],\n",
       " ['retn'],\n",
       " ['sub_100012FD', 'endp'],\n",
       " ['sub_10001301', 'proc', 'near'],\n",
       " [73, 24, '[', 23, '-', '18h', ']'],\n",
       " ['sub_10001301', 'endp'],\n",
       " ['db', '0CCh'],\n",
       " [73, 19, '[', 24, '+', '8', ']'],\n",
       " [96, 19, 19],\n",
       " ['jnz', 'short', 'loc_10001335'],\n",
       " [81, 'dword_10003024', 19],\n",
       " [100, 'short', 'loc_1000135D'],\n",
       " ['dec', 'dword_10003024'],\n",
       " ['loc_10001335:'],\n",
       " [81, 19, '1'],\n",
       " [73, 21, 'ds:_adjust_fdiv'],\n",
       " [73, 21, '[', 21, ']'],\n",
       " [73, 'dword_10003028', 21],\n",
       " ['jnz', 'short', 'loc_10001397'],\n",
       " [72, '80h'],\n",
       " [86, 'ds:malloc'],\n",
       " [96, 19, 19],\n",
       " [109, 21],\n",
       " [73, 'dword_10003030', 19],\n",
       " ['jnz', 'short', 'loc_10001361'],\n",
       " ['loc_1000135D:'],\n",
       " [78, 19, 19],\n",
       " [97, 'short', 'locret_100013DA'],\n",
       " ['loc_10001361:'],\n",
       " [105, 'dword', 'ptr', '[', 19, ']', '0'],\n",
       " [73, 19, 'dword_10003030'],\n",
       " [73, 'dword_1000302C', 19],\n",
       " [86, 'sub_100015C0'],\n",
       " [72, 'offset', 'sub_10001604'],\n",
       " [86, 'sub_100015AE'],\n",
       " [73, 'dword', 'ptr', '[', 24, ']', 'offset', 'unk_10003008'],\n",
       " [72, 'offset', 'unk_10003000'],\n",
       " [86, '_initterm'],\n",
       " ['inc', 'dword_10003024'],\n",
       " [109, 21],\n",
       " [97, 'short', 'loc_100013D6'],\n",
       " ['loc_10001397:'],\n",
       " [96, 19, 19],\n",
       " ['jnz', 'short', 'loc_100013D7'],\n",
       " [73, 19, 'dword_10003030'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'short', 'loc_100013D7'],\n",
       " [97, 'short', 'loc_100013B9'],\n",
       " ['loc_100013A6:'],\n",
       " [73, 21, 'dword_1000302C'],\n",
       " [73, 21, '[', 21, ']'],\n",
       " [96, 21, 21],\n",
       " ['jz', 'short', 'loc_100013B9'],\n",
       " [86, 21],\n",
       " [73, 19, 'dword_10003030'],\n",
       " ['loc_100013B9:'],\n",
       " [74, 'dword_1000302C', '4'],\n",
       " [81, 'dword_1000302C', 19],\n",
       " ['jnb', 'short', 'loc_100013A6'],\n",
       " [72, 19],\n",
       " [86, 'ds:free'],\n",
       " [105, 'dword_10003030', '0'],\n",
       " ['loc_100013D6:'],\n",
       " [109, 21],\n",
       " ['loc_100013D7:'],\n",
       " [78, 19, 19],\n",
       " ['inc', 19],\n",
       " ['locret_100013DA:'],\n",
       " ['retn', '0Ch'],\n",
       " ['public', 'DllEntryPoint'],\n",
       " ['DllEntryPoint:'],\n",
       " [74, 24, '4'],\n",
       " ['pusha'],\n",
       " [73, 20, '10h'],\n",
       " [83, 21, '[', 20, '+', 'ebx*2', '10h', ']'],\n",
       " [72, 21],\n",
       " [73, 21, '1'],\n",
       " [95, 21, '0Ch'],\n",
       " [72, 21],\n",
       " [73, 26, '400h'],\n",
       " [91, 26, '400h'],\n",
       " [72, 26],\n",
       " [72, '0'],\n",
       " [86, 'ds:VirtualAlloc'],\n",
       " [72, 19],\n",
       " [109, 19],\n",
       " [78, 25, 25],\n",
       " [91, 25, 'offset', 'unk_10004138'],\n",
       " [83, 21, '[', 25, ']'],\n",
       " [83, 21, '[', 21, '-', '10004138h', ']'],\n",
       " [72, 21],\n",
       " [72, 19],\n",
       " [73, 26, '[', 25, ']'],\n",
       " [73, 22, 26],\n",
       " [83, 25, '[', 25, '+', '4', ']'],\n",
       " ['loc_10001423:'],\n",
       " [101, 21, 'byte', 'ptr', '[', 25, '+', 22, '-', '1', ']'],\n",
       " [78, 20, 20],\n",
       " [73, '[', 19, '+', 22, '-', '1', ']', 42],\n",
       " ['or', '[', 19, '+', 22, '-', '1', ']', 'cl'],\n",
       " ['dec', 22],\n",
       " ['or', 22, 22],\n",
       " ['jnz', 'short', 'loc_10001423'],\n",
       " [109, 20],\n",
       " [72, 20],\n",
       " [109, 'dword', 'ptr', '[', 20, '+', '1', ']'],\n",
       " [86, 20],\n",
       " ['dw', '74C7h'],\n",
       " ['dd', '105D8B72h', '75FF5653h', '200E808h', '45890000h', '1FE83E4h'],\n",
       " ['dd', '0C73B0E75h', '57530A75h', '0E80875FFh', '0FFFFFEBBh', '574F73Bh'],\n",
       " ['dd', '7503FE83h', '0FF565329h', '0A8E80875h', '85FFFFFEh', '890375C0h'],\n",
       " ['dd', '7D39E47Dh', '0A11374E4h'],\n",
       " ['dd', 'offset', 'dword_10003034'],\n",
       " [81, 19, 26],\n",
       " ['jz', 'short', 'loc_10001496'],\n",
       " [72, 20],\n",
       " [72, 25],\n",
       " [72, 'dword', 'ptr', '[', 23, '+', '8', ']'],\n",
       " [86, 19],\n",
       " [73, '[', 23, '-', '1Ch', ']', 19],\n",
       " ['loc_10001496:'],\n",
       " ['or', 'dword', 'ptr', '[', 23, '-', '4', ']', '0FFFFFFFFh'],\n",
       " [73, 19, '[', 23, '-', '1Ch', ']'],\n",
       " [97, 'short', 'loc_100014B9'],\n",
       " ['sub_1000149F', 'proc', 'near'],\n",
       " [73, 19, '[', 23, '-', '14h', ']'],\n",
       " [73, 21, '[', 19, ']'],\n",
       " [73, 21, '[', 21, ']'],\n",
       " [72, 19],\n",
       " [72, 21],\n",
       " [86, '__CppXcptFilter'],\n",
       " [109, 21],\n",
       " [109, 21],\n",
       " ['retn'],\n",
       " ['sub_1000149F', 'endp'],\n",
       " ['sub_100014B0', 'proc', 'near'],\n",
       " [73, 24, '[', 23, '-', '18h', ']'],\n",
       " ['or', 'dword', 'ptr', '[', 23, '-', '4', ']', '0FFFFFFFFh'],\n",
       " [78, 19, 19],\n",
       " ['loc_100014B9:'],\n",
       " [86, '__SEH_epilog'],\n",
       " ['retn', '0Ch'],\n",
       " ['sub_100014B0', 'endp'],\n",
       " ['sub_100014C1', 'proc', 'near'],\n",
       " ['PerformanceCount=', 'LARGE_INTEGER', 'ptr', '-', '10h'],\n",
       " ['SystemTimeAsFileTime=', '_FILETIME', 'ptr', '-', '8'],\n",
       " [72, 23],\n",
       " [73, 23, 24],\n",
       " [74, 24, '10h'],\n",
       " [73, 19, '___security_cookie'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'short', 'loc_100014D7'],\n",
       " [81, 19, '0BB40E64Eh'],\n",
       " ['jnz', 'short', 'locret_10001525'],\n",
       " ['loc_100014D7:'],\n",
       " [72, 25],\n",
       " [83, 19, '[', 23, '+', 'SystemTimeAsFileTime', ']'],\n",
       " [72, 19],\n",
       " [86, 'ds:GetSystemTimeAsFileTime'],\n",
       " [73, 25, '[', 23, '+', 'SystemTimeAsFileTime.dwHighDateTime', ']'],\n",
       " [78, 25, '[', 23, '+', 'SystemTimeAsFileTime.dwLowDateTime', ']'],\n",
       " [86, 'ds:GetCurrentProcessId'],\n",
       " [78, 25, 19],\n",
       " [86, 'ds:GetCurrentThreadId'],\n",
       " [78, 25, 19],\n",
       " [86, 'ds:GetTickCount'],\n",
       " [78, 25, 19],\n",
       " [83, 19, '[', 23, '+', 'PerformanceCount', ']'],\n",
       " [72, 19],\n",
       " [86, 'ds:QueryPerformanceCounter'],\n",
       " [73, 19, 'dword', 'ptr', '[', 23, '+', 'PerformanceCount', '4', ']'],\n",
       " [78, 19, 'dword', 'ptr', '[', 23, '+', 'PerformanceCount', ']'],\n",
       " [78, 25, 19],\n",
       " [73, '___security_cookie', 25],\n",
       " ['jnz', 'short', 'loc_10001524'],\n",
       " [73, '___security_cookie', '0BB40E64Eh'],\n",
       " ['loc_10001524:'],\n",
       " [109, 25],\n",
       " ['locret_10001525:'],\n",
       " [89],\n",
       " ['retn'],\n",
       " ['sub_100014C1', 'endp'],\n",
       " ['align', '4'],\n",
       " ['align', '10h'],\n",
       " ['sub_10001588', 'proc', 'near'],\n",
       " ['arg_0', '=', 'dword', 'ptr', '4'],\n",
       " [81, 'dword_10003030', '0FFFFFFFFh'],\n",
       " ['jnz', 'short', 'loc_10001597'],\n",
       " [97, 'ds:_onexit'],\n",
       " ['loc_10001597:'],\n",
       " [72, 'offset', 'dword_1000302C'],\n",
       " [72, 'offset', 'dword_10003030'],\n",
       " [72, '[', 24, '+', '8', 'arg_0', ']'],\n",
       " [86, '__dllonexit'],\n",
       " [91, 24, '0Ch'],\n",
       " ['retn'],\n",
       " ['sub_10001588', 'endp'],\n",
       " ['sub_100015AE', 'proc', 'near'],\n",
       " ['arg_0', '=', 'dword', 'ptr', '4'],\n",
       " [72, '[', 24, '+', 'arg_0', ']'],\n",
       " [86, 'sub_10001588'],\n",
       " ['neg', 19],\n",
       " ['sbb', 19, 19],\n",
       " ['neg', 19],\n",
       " [109, 21],\n",
       " ['dec', 19],\n",
       " ['retn'],\n",
       " ['sub_100015AE', 'endp'],\n",
       " ['sub_100015C0', 'proc', 'near'],\n",
       " ['ms_exc', '=', 'CPPEH_RECORD', 'ptr', '-', '18h'],\n",
       " [72, '0Ch'],\n",
       " [72, 'offset', 'stru_10002118'],\n",
       " [86, '__SEH_prolog'],\n",
       " [73, '[', 23, '+', 'var_1C', ']', 'offset', 'unk_100021FC'],\n",
       " ['loc_100015D3:'],\n",
       " [81, '[', 23, '+', 'var_1C', ']', 'offset', 'unk_100021FC'],\n",
       " ['jnb', 'short', 'loc_100015FE'],\n",
       " [105, '[', 23, '+', 'ms_exc.registration.TryLevel', ']', '0'],\n",
       " [73, 19, '[', 23, '+', 'var_1C', ']'],\n",
       " [73, 19, '[', 19, ']'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'short', 'loc_100015F4'],\n",
       " [86, 19],\n",
       " [97, 'short', 'loc_100015F4'],\n",
       " ['loc_100015ED:'],\n",
       " [78, 19, 19],\n",
       " ['inc', 19],\n",
       " ['retn'],\n",
       " ['loc_100015F1:'],\n",
       " [73, 24, '[', 23, '+', 'ms_exc.old_esp', ']'],\n",
       " ['loc_100015F4:'],\n",
       " ['or', '[', 23, '+', 'ms_exc.registration.TryLevel', ']', '0FFFFFFFFh'],\n",
       " [91, '[', 23, '+', 'var_1C', ']', '4'],\n",
       " [97, 'short', 'loc_100015D3'],\n",
       " ['loc_100015FE:'],\n",
       " [86, '__SEH_epilog'],\n",
       " ['retn'],\n",
       " ['sub_100015C0', 'endp'],\n",
       " ['sub_10001604', 'proc', 'near'],\n",
       " ['ms_exc', '=', 'CPPEH_RECORD', 'ptr', '-', '18h'],\n",
       " [72, '0Ch'],\n",
       " [72, 'offset', 'stru_10002128'],\n",
       " [86, '__SEH_prolog'],\n",
       " [73, '[', 23, '+', 'var_1C', ']', 'offset', 'unk_10002204'],\n",
       " ['loc_10001617:'],\n",
       " [81, '[', 23, '+', 'var_1C', ']', 'offset', 'unk_10002204'],\n",
       " ['jnb', 'short', 'loc_10001642'],\n",
       " [105, '[', 23, '+', 'ms_exc.registration.TryLevel', ']', '0'],\n",
       " [73, 19, '[', 23, '+', 'var_1C', ']'],\n",
       " [73, 19, '[', 19, ']'],\n",
       " [96, 19, 19],\n",
       " ['jz', 'short', 'loc_10001638'],\n",
       " [86, 19],\n",
       " [97, 'short', 'loc_10001638'],\n",
       " ['loc_10001631:'],\n",
       " [78, 19, 19],\n",
       " ['inc', 19],\n",
       " ['retn'],\n",
       " ['loc_10001635:'],\n",
       " [73, 24, '[', 23, '+', 'ms_exc.old_esp', ']'],\n",
       " ['loc_10001638:'],\n",
       " ['or', '[', 23, '+', 'ms_exc.registration.TryLevel', ']', '0FFFFFFFFh'],\n",
       " [91, '[', 23, '+', 'var_1C', ']', '4'],\n",
       " [97, 'short', 'loc_10001617'],\n",
       " ['loc_10001642:'],\n",
       " [86, '__SEH_epilog'],\n",
       " ['retn'],\n",
       " ['sub_10001604', 'endp'],\n",
       " [81, 'dword', 'ptr', '[', 24, '+', '8', ']', '1'],\n",
       " ['jnz', 'short', 'loc_10001668'],\n",
       " [81, 'dword_10003034', '0'],\n",
       " ['jnz', 'short', 'loc_10001668'],\n",
       " [72, 'dword', 'ptr', '[', 24, '+', '4', ']'],\n",
       " [86, 'ds:DisableThreadLibraryCalls'],\n",
       " ['loc_10001668:'],\n",
       " [78, 19, 19],\n",
       " ['inc', 19],\n",
       " ['retn', '0Ch'],\n",
       " ['align', '10h'],\n",
       " ['sub_10001680', 'proc', 'near'],\n",
       " [83, 21, '[', 23, '-', '28h', ']'],\n",
       " [97],\n",
       " ['sub_10001680', 'endp'],\n",
       " ['sub_10001689', 'proc', 'near'],\n",
       " [73, 19, '[', 23, '-', '2Ch', ']'],\n",
       " [105, 19, '1'],\n",
       " ['jz', 'locret_100016A2'],\n",
       " [105, 'dword', 'ptr', '[', 23, '-', '2Ch', ']', '0FFFFFFFEh'],\n",
       " [73, 21, '[', 23, '+', '4', ']'],\n",
       " [97],\n",
       " ['locret_100016A2:'],\n",
       " ['retn'],\n",
       " ['sub_10001689', 'endp'],\n",
       " ['SEH_10001000', 'proc', 'near'],\n",
       " [73, 19, 'offset', 'stru_10002218'],\n",
       " [97, '__CxxFrameHandler'],\n",
       " ['SEH_10001000', 'endp'],\n",
       " ['align', '200h'],\n",
       " ['dd', '200h', 'dup(?)'],\n",
       " ['ends']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_arr_3[0][\"text_arr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = ['hello', 'world', '=', 'dword', 'ptr', '32Ch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'=' in test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_arr_4 = [{ \n",
    "#     \"text_arr\": extra_processing(struct_dict[\"text_arr\"]), \n",
    "#     \"data_arr\": extra_processing(struct_dict[\"data_arr\"]), \n",
    "#     \"file_name\": struct_dict[\"file_name\"] \n",
    "# } for struct_dict in dataset_arr_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_arr_4[0][\"text_arr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_arr_4[0][\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_arr_4[0][\"data_arr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = '[esp-4Ch]'\n",
    "# temp = ['mov', 'ecx', '[esp+30h+arg_8]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2 = temp.split('[')\n",
    "# for i in range(1, len(temp2), 2):\n",
    "#     temp2.insert(i, '[')\n",
    "# temp2 = [ token for token in temp2 if token ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, len(temp2), 2):\n",
    "#     temp2.insert(i, '-')\n",
    "# temp2 = [ token for token in temp2 if token ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2 = gen('[', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3 = gen(']', temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3 = gen('+', temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Iterable\n",
    "# def flatten(coll):\n",
    "#     for i in coll:\n",
    "#             if isinstance(i, Iterable) and not isinstance(i, str):\n",
    "#                 for subc in flatten(i):\n",
    "#                     yield subc\n",
    "#             else:\n",
    "#                 yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_to_strings(listOfLists):\n",
    "#     \"\"\"Flatten a list of (lists of (lists of strings)) for any level \n",
    "#     of nesting\"\"\"\n",
    "#     result = []\n",
    "\n",
    "#     for i in listOfLists:\n",
    "#         # Only append if i is a basestring (superclass of string)\n",
    "#         if isinstance(i, str):\n",
    "#             result.append(i)\n",
    "#         # Otherwise call this function recursively\n",
    "#         else:\n",
    "#             result.extend(flatten_to_strings(i))\n",
    "#     return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
