{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('./utils/'))\n",
    "import util as utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some memory clean-up\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create and compile the neural network model (Reusability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "    model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store relevant directory paths for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.abspath('./dataset/')\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the names (without extension) of all files in the three folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = [ os.path.splitext(file)[0] for file in os.listdir(train_dir) ]\n",
    "test_files = [ os.path.splitext(file)[0] for file in os.listdir(test_dir) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store trainLabels.csv (containing the label for each file in the dataset) into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_labels = { filename: label for filename, label in pd.read_csv('./trainLabels.csv').get_values() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `data_labels`, map `train_file` and `test_files` to their respective labels and store them into `train_labels` and `test_labels` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = [ data_labels.get(filename, filename) for filename in train_files ]\n",
    "test_labels = [ data_labels.get(filename, filename) for filename in test_files ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With labels stored in their variables, next load the dataset as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [ utils.load_image_as_np(os.path.join(train_dir, (filename+'.png'))) for filename in train_files ]\n",
    "test_set = [ utils.load_image_as_np(os.path.join(test_dir, (filename+'.png'))) for filename in test_files ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing of labels\n",
    "The training labels range from 1 - 9 by default.<br/>\n",
    "Change this to a range of 0 - 8 instead.<br/>\n",
    "This is to ensure that the results of one-hot encoding of the labels do not contain an extra column full of '0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = [ (i - 1) for i in train_labels ]\n",
    "test_labels = [ (i - 1) for i in test_labels ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, perform one-hot encoding of the labels with the help of the keras utility function, `to_categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing of data\n",
    "`train_set` and `test_set` are two lists containing numpy arrays representing images from the respective data images<br/>\n",
    "Neural network implemented in Keras generally expect numpy arrays as input data, NOT lists.\n",
    "Hence, the first step is to convert the lists to numpy arrays using `np.asarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = np.asarray(train_set)\n",
    "test_set = np.asarray(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, divide each byte (which represents the grayscale value of each pixel in an image) by 255 to bring all the values to a range of 0 to 1. This does good to the model (Manipulating smaller numbers is better than manipulating larger ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = train_set.astype('float32') / 255\n",
    "test_set = test_set.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set.shape:        (7610, 128, 128, 1)\n",
      "test_set.shape:         (3258, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print('train_set.shape:       ', train_set.shape)\n",
    "print('test_set.shape:        ', test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_set) // k\n",
    "num_epochs = 50\n",
    "all_histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold # 0\n",
      "(14562, 128, 128, 1)\n",
      "(14562, 9)\n",
      "Train on 14562 samples, validate on 1902 samples\n",
      "Epoch 1/50\n",
      "14562/14562 [==============================] - 11s - loss: 1.5238 - acc: 0.4352 - val_loss: 0.9723 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.8941 - acc: 0.7043 - val_loss: 0.7403 - val_acc: 0.7723\n",
      "Epoch 3/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.7363 - acc: 0.7710 - val_loss: 0.7556 - val_acc: 0.7466\n",
      "Epoch 4/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.6145 - acc: 0.8070 - val_loss: 0.9853 - val_acc: 0.7329\n",
      "Epoch 5/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.5867 - acc: 0.8335 - val_loss: 0.4893 - val_acc: 0.8601\n",
      "Epoch 6/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.4546 - acc: 0.8698 - val_loss: 0.5630 - val_acc: 0.8423\n",
      "Epoch 7/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.4005 - acc: 0.8937 - val_loss: 0.4376 - val_acc: 0.8817\n",
      "Epoch 8/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.3430 - acc: 0.9056 - val_loss: 0.3695 - val_acc: 0.9127\n",
      "Epoch 9/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.3250 - acc: 0.9118 - val_loss: 0.3005 - val_acc: 0.9269\n",
      "Epoch 10/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.2850 - acc: 0.9260 - val_loss: 0.3280 - val_acc: 0.9143\n",
      "Epoch 11/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.2438 - acc: 0.9335 - val_loss: 0.2741 - val_acc: 0.9206\n",
      "Epoch 12/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.2207 - acc: 0.9388 - val_loss: 0.2839 - val_acc: 0.9338\n",
      "Epoch 13/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1998 - acc: 0.9418 - val_loss: 0.2663 - val_acc: 0.9411\n",
      "Epoch 14/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1672 - acc: 0.9513 - val_loss: 0.3403 - val_acc: 0.9385\n",
      "Epoch 15/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1575 - acc: 0.9559 - val_loss: 0.3071 - val_acc: 0.9285\n",
      "Epoch 16/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1784 - acc: 0.9484 - val_loss: 0.2606 - val_acc: 0.9469\n",
      "Epoch 17/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1124 - acc: 0.9677 - val_loss: 0.2878 - val_acc: 0.9411\n",
      "Epoch 18/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1211 - acc: 0.9661 - val_loss: 0.2499 - val_acc: 0.9532\n",
      "Epoch 19/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1547 - acc: 0.9626 - val_loss: 0.2547 - val_acc: 0.9458\n",
      "Epoch 20/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0872 - acc: 0.9761 - val_loss: 0.3393 - val_acc: 0.9401\n",
      "Epoch 21/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0879 - acc: 0.9749 - val_loss: 0.3292 - val_acc: 0.9464\n",
      "Epoch 22/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.1243 - acc: 0.9676 - val_loss: 0.2868 - val_acc: 0.9490\n",
      "Epoch 23/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0737 - acc: 0.9808 - val_loss: 0.4498 - val_acc: 0.9348\n",
      "Epoch 24/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0925 - acc: 0.9770 - val_loss: 0.2953 - val_acc: 0.9527\n",
      "Epoch 25/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0716 - acc: 0.9791 - val_loss: 0.3125 - val_acc: 0.9474\n",
      "Epoch 26/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0733 - acc: 0.9793 - val_loss: 0.2889 - val_acc: 0.9501\n",
      "Epoch 27/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0698 - acc: 0.9788 - val_loss: 0.2731 - val_acc: 0.9506\n",
      "Epoch 28/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0514 - acc: 0.9845 - val_loss: 0.2849 - val_acc: 0.9506\n",
      "Epoch 29/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0514 - acc: 0.9854 - val_loss: 0.2828 - val_acc: 0.9522\n",
      "Epoch 30/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0576 - acc: 0.9835 - val_loss: 0.2878 - val_acc: 0.9543\n",
      "Epoch 31/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0634 - acc: 0.9829 - val_loss: 0.2730 - val_acc: 0.9595\n",
      "Epoch 32/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0424 - acc: 0.9865 - val_loss: 0.2588 - val_acc: 0.9564\n",
      "Epoch 33/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0563 - acc: 0.9839 - val_loss: 0.2855 - val_acc: 0.9585\n",
      "Epoch 34/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0336 - acc: 0.9888 - val_loss: 0.3177 - val_acc: 0.9543\n",
      "Epoch 35/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0623 - acc: 0.9839 - val_loss: 0.3046 - val_acc: 0.9564\n",
      "Epoch 36/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0390 - acc: 0.9890 - val_loss: 0.2905 - val_acc: 0.9558\n",
      "Epoch 37/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0439 - acc: 0.9883 - val_loss: 0.2733 - val_acc: 0.9600\n",
      "Epoch 38/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0392 - acc: 0.9885 - val_loss: 0.3796 - val_acc: 0.9432\n",
      "Epoch 39/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0398 - acc: 0.9883 - val_loss: 0.2810 - val_acc: 0.9585\n",
      "Epoch 40/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0319 - acc: 0.9911 - val_loss: 0.3018 - val_acc: 0.9579\n",
      "Epoch 41/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0435 - acc: 0.9873 - val_loss: 0.3116 - val_acc: 0.9569\n",
      "Epoch 42/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0273 - acc: 0.9913 - val_loss: 0.3398 - val_acc: 0.9532\n",
      "Epoch 43/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0587 - acc: 0.9852 - val_loss: 0.2912 - val_acc: 0.9579\n",
      "Epoch 44/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0299 - acc: 0.9924 - val_loss: 0.3012 - val_acc: 0.9627\n",
      "Epoch 45/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0445 - acc: 0.9877 - val_loss: 0.3204 - val_acc: 0.9585\n",
      "Epoch 46/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0193 - acc: 0.9945 - val_loss: 0.3511 - val_acc: 0.9585\n",
      "Epoch 47/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0242 - acc: 0.9932 - val_loss: 0.3492 - val_acc: 0.9574\n",
      "Epoch 48/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0407 - acc: 0.9881 - val_loss: 0.3238 - val_acc: 0.9579\n",
      "Epoch 49/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0204 - acc: 0.9946 - val_loss: 0.3350 - val_acc: 0.9543\n",
      "Epoch 50/50\n",
      "14562/14562 [==============================] - 6s - loss: 0.0236 - acc: 0.9940 - val_loss: 0.3502 - val_acc: 0.9574\n",
      "Processed fold # 0\n",
      "\n",
      "\n",
      "Processing fold # 1\n",
      "(14292, 128, 128, 1)\n",
      "(14292, 9)\n",
      "Train on 14292 samples, validate on 1902 samples\n",
      "Epoch 1/50\n",
      "14292/14292 [==============================] - 7s - loss: 1.5886 - acc: 0.4399 - val_loss: 1.0113 - val_acc: 0.6341\n",
      "Epoch 2/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.9405 - acc: 0.6950 - val_loss: 1.0388 - val_acc: 0.6293\n",
      "Epoch 3/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.7740 - acc: 0.7627 - val_loss: 0.7459 - val_acc: 0.7419\n",
      "Epoch 4/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.6472 - acc: 0.8060 - val_loss: 0.4833 - val_acc: 0.8496\n",
      "Epoch 5/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.5299 - acc: 0.8455 - val_loss: 0.4205 - val_acc: 0.8680\n",
      "Epoch 6/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.4563 - acc: 0.8752 - val_loss: 0.3098 - val_acc: 0.9096\n",
      "Epoch 7/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.3652 - acc: 0.8982 - val_loss: 0.3126 - val_acc: 0.9027\n",
      "Epoch 8/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.3368 - acc: 0.9073 - val_loss: 0.3001 - val_acc: 0.9106\n",
      "Epoch 9/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.3144 - acc: 0.9131 - val_loss: 0.3201 - val_acc: 0.9164\n",
      "Epoch 10/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.2452 - acc: 0.9306 - val_loss: 0.2306 - val_acc: 0.9422\n",
      "Epoch 11/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.2250 - acc: 0.9380 - val_loss: 0.3060 - val_acc: 0.9059\n",
      "Epoch 12/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.2241 - acc: 0.9365 - val_loss: 0.2188 - val_acc: 0.9501\n",
      "Epoch 13/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1740 - acc: 0.9522 - val_loss: 0.3811 - val_acc: 0.8938\n",
      "Epoch 14/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1934 - acc: 0.9462 - val_loss: 0.2158 - val_acc: 0.9464\n",
      "Epoch 15/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1610 - acc: 0.9539 - val_loss: 0.2036 - val_acc: 0.9511\n",
      "Epoch 16/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1450 - acc: 0.9588 - val_loss: 0.2415 - val_acc: 0.9390\n",
      "Epoch 17/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1636 - acc: 0.9593 - val_loss: 0.2092 - val_acc: 0.9537\n",
      "Epoch 18/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1265 - acc: 0.9664 - val_loss: 0.2389 - val_acc: 0.9537\n",
      "Epoch 19/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1368 - acc: 0.9633 - val_loss: 0.2334 - val_acc: 0.9416\n",
      "Epoch 20/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0964 - acc: 0.9719 - val_loss: 0.2100 - val_acc: 0.9543\n",
      "Epoch 21/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1388 - acc: 0.9626 - val_loss: 0.2098 - val_acc: 0.9543\n",
      "Epoch 22/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0899 - acc: 0.9749 - val_loss: 0.2140 - val_acc: 0.9564\n",
      "Epoch 23/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0954 - acc: 0.9717 - val_loss: 0.1858 - val_acc: 0.9632\n",
      "Epoch 24/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1394 - acc: 0.9651 - val_loss: 0.1952 - val_acc: 0.9611\n",
      "Epoch 25/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0613 - acc: 0.9821 - val_loss: 0.2361 - val_acc: 0.9437\n",
      "Epoch 26/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0652 - acc: 0.9820 - val_loss: 0.2003 - val_acc: 0.9616\n",
      "Epoch 27/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0696 - acc: 0.9797 - val_loss: 0.2883 - val_acc: 0.9359\n",
      "Epoch 28/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1032 - acc: 0.9816 - val_loss: 0.2139 - val_acc: 0.9579\n",
      "Epoch 29/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0675 - acc: 0.9815 - val_loss: 0.2001 - val_acc: 0.9621\n",
      "Epoch 30/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0567 - acc: 0.9834 - val_loss: 0.2145 - val_acc: 0.9632\n",
      "Epoch 31/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.1079 - acc: 0.9752 - val_loss: 0.2062 - val_acc: 0.9616\n",
      "Epoch 32/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0622 - acc: 0.9813 - val_loss: 0.2223 - val_acc: 0.9653\n",
      "Epoch 33/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0405 - acc: 0.9884 - val_loss: 0.2427 - val_acc: 0.9527\n",
      "Epoch 34/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0708 - acc: 0.9819 - val_loss: 0.2294 - val_acc: 0.9548\n",
      "Epoch 35/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0488 - acc: 0.9871 - val_loss: 0.2735 - val_acc: 0.9479\n",
      "Epoch 36/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0518 - acc: 0.9858 - val_loss: 0.2255 - val_acc: 0.9616\n",
      "Epoch 37/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0629 - acc: 0.9829 - val_loss: 0.2066 - val_acc: 0.9616\n",
      "Epoch 38/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0327 - acc: 0.9910 - val_loss: 0.2559 - val_acc: 0.9621\n",
      "Epoch 39/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0606 - acc: 0.9840 - val_loss: 0.2260 - val_acc: 0.9621\n",
      "Epoch 40/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0443 - acc: 0.9880 - val_loss: 0.2251 - val_acc: 0.9627\n",
      "Epoch 41/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0706 - acc: 0.9840 - val_loss: 0.2548 - val_acc: 0.9621\n",
      "Epoch 42/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0383 - acc: 0.9903 - val_loss: 0.2357 - val_acc: 0.9600\n",
      "Epoch 43/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0364 - acc: 0.9906 - val_loss: 0.2563 - val_acc: 0.9569\n",
      "Epoch 44/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0333 - acc: 0.9918 - val_loss: 0.2545 - val_acc: 0.9579\n",
      "Epoch 45/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0495 - acc: 0.9872 - val_loss: 0.2358 - val_acc: 0.9637\n",
      "Epoch 46/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0289 - acc: 0.9922 - val_loss: 0.2676 - val_acc: 0.9642\n",
      "Epoch 47/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0858 - acc: 0.9813 - val_loss: 0.2428 - val_acc: 0.9637\n",
      "Epoch 48/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0226 - acc: 0.9945 - val_loss: 0.2423 - val_acc: 0.9616\n",
      "Epoch 49/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0438 - acc: 0.9888 - val_loss: 0.2436 - val_acc: 0.9648\n",
      "Epoch 50/50\n",
      "14292/14292 [==============================] - 6s - loss: 0.0375 - acc: 0.9901 - val_loss: 0.2339 - val_acc: 0.9658\n",
      "Processed fold # 1\n",
      "\n",
      "\n",
      "Processing fold # 2\n",
      "(14166, 128, 128, 1)\n",
      "(14166, 9)\n",
      "Train on 14166 samples, validate on 1902 samples\n",
      "Epoch 1/50\n",
      "14166/14166 [==============================] - 7s - loss: 1.5207 - acc: 0.4699 - val_loss: 0.9616 - val_acc: 0.6225\n",
      "Epoch 2/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.8535 - acc: 0.7200 - val_loss: 0.6499 - val_acc: 0.7923\n",
      "Epoch 3/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.7267 - acc: 0.7612 - val_loss: 0.5392 - val_acc: 0.8223\n",
      "Epoch 4/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.5607 - acc: 0.8294 - val_loss: 0.5629 - val_acc: 0.8502\n",
      "Epoch 5/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.5412 - acc: 0.8368 - val_loss: 0.4656 - val_acc: 0.8575\n",
      "Epoch 6/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.4869 - acc: 0.8631 - val_loss: 0.4129 - val_acc: 0.8707\n",
      "Epoch 7/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.3981 - acc: 0.8849 - val_loss: 0.3380 - val_acc: 0.9138\n",
      "Epoch 8/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.3264 - acc: 0.9082 - val_loss: 0.3218 - val_acc: 0.9238\n",
      "Epoch 9/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.3271 - acc: 0.9108 - val_loss: 0.4961 - val_acc: 0.8696\n",
      "Epoch 10/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.2730 - acc: 0.9281 - val_loss: 0.2691 - val_acc: 0.9374\n",
      "Epoch 11/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.2319 - acc: 0.9360 - val_loss: 0.2625 - val_acc: 0.9401\n",
      "Epoch 12/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.2062 - acc: 0.9472 - val_loss: 0.3573 - val_acc: 0.8991\n",
      "Epoch 13/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1965 - acc: 0.9440 - val_loss: 0.2381 - val_acc: 0.9395\n",
      "Epoch 14/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1676 - acc: 0.9543 - val_loss: 0.3139 - val_acc: 0.9164\n",
      "Epoch 15/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1521 - acc: 0.9600 - val_loss: 0.2995 - val_acc: 0.9437\n",
      "Epoch 16/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1573 - acc: 0.9573 - val_loss: 0.3112 - val_acc: 0.9274\n",
      "Epoch 17/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1343 - acc: 0.9636 - val_loss: 0.2714 - val_acc: 0.9317\n",
      "Epoch 18/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1301 - acc: 0.9638 - val_loss: 0.2530 - val_acc: 0.9469\n",
      "Epoch 19/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0982 - acc: 0.9729 - val_loss: 0.2376 - val_acc: 0.9458\n",
      "Epoch 20/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0974 - acc: 0.9732 - val_loss: 0.2689 - val_acc: 0.9369\n",
      "Epoch 21/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0913 - acc: 0.9756 - val_loss: 0.2638 - val_acc: 0.9422\n",
      "Epoch 22/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.1168 - acc: 0.9688 - val_loss: 0.2057 - val_acc: 0.9569\n",
      "Epoch 23/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0763 - acc: 0.9778 - val_loss: 0.3386 - val_acc: 0.9232\n",
      "Epoch 24/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0639 - acc: 0.9819 - val_loss: 0.2155 - val_acc: 0.9558\n",
      "Epoch 25/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0684 - acc: 0.9795 - val_loss: 0.3368 - val_acc: 0.9280\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14166/14166 [==============================] - 6s - loss: 0.0785 - acc: 0.9783 - val_loss: 0.2378 - val_acc: 0.9527\n",
      "Epoch 27/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0937 - acc: 0.9757 - val_loss: 0.3709 - val_acc: 0.9295\n",
      "Epoch 28/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0470 - acc: 0.9872 - val_loss: 0.2116 - val_acc: 0.9606\n",
      "Epoch 29/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0613 - acc: 0.9838 - val_loss: 0.2404 - val_acc: 0.9522\n",
      "Epoch 30/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0754 - acc: 0.9792 - val_loss: 0.2160 - val_acc: 0.9595\n",
      "Epoch 31/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0492 - acc: 0.9871 - val_loss: 0.2029 - val_acc: 0.9642\n",
      "Epoch 32/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0665 - acc: 0.9809 - val_loss: 0.2006 - val_acc: 0.9606\n",
      "Epoch 33/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0426 - acc: 0.9884 - val_loss: 0.3028 - val_acc: 0.9317\n",
      "Epoch 34/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0426 - acc: 0.9876 - val_loss: 0.2364 - val_acc: 0.9611\n",
      "Epoch 35/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0435 - acc: 0.9876 - val_loss: 0.2180 - val_acc: 0.9632\n",
      "Epoch 36/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0669 - acc: 0.9838 - val_loss: 0.2448 - val_acc: 0.9621\n",
      "Epoch 37/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0334 - acc: 0.9912 - val_loss: 0.2265 - val_acc: 0.9579\n",
      "Epoch 38/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0387 - acc: 0.9900 - val_loss: 0.3033 - val_acc: 0.9495\n",
      "Epoch 39/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0345 - acc: 0.9915 - val_loss: 0.2756 - val_acc: 0.9585\n",
      "Epoch 40/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0497 - acc: 0.9890 - val_loss: 0.2380 - val_acc: 0.9606\n",
      "Epoch 41/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0445 - acc: 0.9876 - val_loss: 0.2348 - val_acc: 0.9600\n",
      "Epoch 42/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0314 - acc: 0.9925 - val_loss: 0.2450 - val_acc: 0.9537\n",
      "Epoch 43/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0442 - acc: 0.9886 - val_loss: 0.2420 - val_acc: 0.9621\n",
      "Epoch 44/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0228 - acc: 0.9936 - val_loss: 0.3039 - val_acc: 0.9416\n",
      "Epoch 45/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0238 - acc: 0.9936 - val_loss: 0.2433 - val_acc: 0.9648\n",
      "Epoch 46/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0546 - acc: 0.9871 - val_loss: 0.2475 - val_acc: 0.9627\n",
      "Epoch 47/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0446 - acc: 0.9891 - val_loss: 0.2585 - val_acc: 0.9621\n",
      "Epoch 48/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0193 - acc: 0.9951 - val_loss: 0.4757 - val_acc: 0.9264\n",
      "Epoch 49/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0523 - acc: 0.9895 - val_loss: 0.2769 - val_acc: 0.9658\n",
      "Epoch 50/50\n",
      "14166/14166 [==============================] - 6s - loss: 0.0157 - acc: 0.9959 - val_loss: 0.2819 - val_acc: 0.9569\n",
      "Processed fold # 2\n",
      "\n",
      "\n",
      "Processing fold # 3\n",
      "(14175, 128, 128, 1)\n",
      "(14175, 9)\n",
      "Train on 14175 samples, validate on 1902 samples\n",
      "Epoch 1/50\n",
      "14175/14175 [==============================] - 7s - loss: 1.5879 - acc: 0.4030 - val_loss: 1.0475 - val_acc: 0.6688\n",
      "Epoch 2/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.9810 - acc: 0.6563 - val_loss: 0.7154 - val_acc: 0.7787\n",
      "Epoch 3/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.7755 - acc: 0.7357 - val_loss: 0.6053 - val_acc: 0.8249\n",
      "Epoch 4/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.6456 - acc: 0.7972 - val_loss: 0.5971 - val_acc: 0.8023\n",
      "Epoch 5/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.5527 - acc: 0.8235 - val_loss: 0.6210 - val_acc: 0.8433\n",
      "Epoch 6/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.4876 - acc: 0.8589 - val_loss: 0.4312 - val_acc: 0.8885\n",
      "Epoch 7/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.4091 - acc: 0.8844 - val_loss: 0.5425 - val_acc: 0.8686\n",
      "Epoch 8/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.3551 - acc: 0.9039 - val_loss: 0.4787 - val_acc: 0.8733\n",
      "Epoch 9/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.2994 - acc: 0.9199 - val_loss: 0.3552 - val_acc: 0.9201\n",
      "Epoch 10/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.2638 - acc: 0.9325 - val_loss: 0.3976 - val_acc: 0.8980\n",
      "Epoch 11/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.2402 - acc: 0.9386 - val_loss: 0.3676 - val_acc: 0.9117\n",
      "Epoch 12/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.2003 - acc: 0.9468 - val_loss: 0.3819 - val_acc: 0.9206\n",
      "Epoch 13/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1919 - acc: 0.9491 - val_loss: 0.2866 - val_acc: 0.9443\n",
      "Epoch 14/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1835 - acc: 0.9529 - val_loss: 0.3185 - val_acc: 0.9096\n",
      "Epoch 15/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1810 - acc: 0.9524 - val_loss: 0.4409 - val_acc: 0.9012\n",
      "Epoch 16/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1259 - acc: 0.9671 - val_loss: 0.3137 - val_acc: 0.9264\n",
      "Epoch 17/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1489 - acc: 0.9620 - val_loss: 0.2610 - val_acc: 0.9490\n",
      "Epoch 18/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1313 - acc: 0.9644 - val_loss: 0.2875 - val_acc: 0.9464\n",
      "Epoch 19/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1128 - acc: 0.9695 - val_loss: 0.5185 - val_acc: 0.8612\n",
      "Epoch 20/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1112 - acc: 0.9697 - val_loss: 0.5636 - val_acc: 0.8854\n",
      "Epoch 21/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1031 - acc: 0.9720 - val_loss: 0.2384 - val_acc: 0.9532\n",
      "Epoch 22/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.1022 - acc: 0.9741 - val_loss: 0.2462 - val_acc: 0.9511\n",
      "Epoch 23/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0740 - acc: 0.9809 - val_loss: 0.3365 - val_acc: 0.9385\n",
      "Epoch 24/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0823 - acc: 0.9781 - val_loss: 0.3122 - val_acc: 0.9511\n",
      "Epoch 25/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0674 - acc: 0.9817 - val_loss: 0.2995 - val_acc: 0.9453\n",
      "Epoch 26/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0718 - acc: 0.9812 - val_loss: 0.2686 - val_acc: 0.9548\n",
      "Epoch 27/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0673 - acc: 0.9835 - val_loss: 0.2517 - val_acc: 0.9543\n",
      "Epoch 28/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0638 - acc: 0.9840 - val_loss: 0.2739 - val_acc: 0.9527\n",
      "Epoch 29/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0603 - acc: 0.9828 - val_loss: 0.2606 - val_acc: 0.9569\n",
      "Epoch 30/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0612 - acc: 0.9838 - val_loss: 0.2536 - val_acc: 0.9579\n",
      "Epoch 31/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0500 - acc: 0.9869 - val_loss: 0.2703 - val_acc: 0.9532\n",
      "Epoch 32/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0711 - acc: 0.9823 - val_loss: 0.2596 - val_acc: 0.9606\n",
      "Epoch 33/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0428 - acc: 0.9885 - val_loss: 0.2694 - val_acc: 0.9574\n",
      "Epoch 34/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0597 - acc: 0.9854 - val_loss: 0.2659 - val_acc: 0.9611\n",
      "Epoch 35/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0466 - acc: 0.9871 - val_loss: 0.2421 - val_acc: 0.9606\n",
      "Epoch 36/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0455 - acc: 0.9885 - val_loss: 0.2754 - val_acc: 0.9606\n",
      "Epoch 37/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0343 - acc: 0.9912 - val_loss: 0.3026 - val_acc: 0.9511\n",
      "Epoch 38/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0532 - acc: 0.9871 - val_loss: 0.2662 - val_acc: 0.9600\n",
      "Epoch 39/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0378 - acc: 0.9910 - val_loss: 0.2830 - val_acc: 0.9611\n",
      "Epoch 40/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0371 - acc: 0.9912 - val_loss: 0.3437 - val_acc: 0.9479\n",
      "Epoch 41/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0354 - acc: 0.9903 - val_loss: 0.3584 - val_acc: 0.9485\n",
      "Epoch 42/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0333 - acc: 0.9908 - val_loss: 0.3075 - val_acc: 0.9574\n",
      "Epoch 43/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0480 - acc: 0.9874 - val_loss: 0.2948 - val_acc: 0.9579\n",
      "Epoch 44/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0224 - acc: 0.9946 - val_loss: 0.3806 - val_acc: 0.9516\n",
      "Epoch 45/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0348 - acc: 0.9901 - val_loss: 0.3154 - val_acc: 0.9537\n",
      "Epoch 46/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0407 - acc: 0.9897 - val_loss: 0.2983 - val_acc: 0.9558\n",
      "Epoch 47/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0360 - acc: 0.9916 - val_loss: 0.3443 - val_acc: 0.9548\n",
      "Epoch 48/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0215 - acc: 0.9946 - val_loss: 0.3385 - val_acc: 0.9548\n",
      "Epoch 49/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0764 - acc: 0.9847 - val_loss: 0.3046 - val_acc: 0.9579\n",
      "Epoch 50/50\n",
      "14175/14175 [==============================] - 6s - loss: 0.0166 - acc: 0.9960 - val_loss: 0.3129 - val_acc: 0.9585\n",
      "Processed fold # 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('Processing fold #', i)\n",
    "    val_set = train_set[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_labels = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_set = np.concatenate(\n",
    "        [train_set[:i * num_val_samples], \n",
    "         train_set[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    \n",
    "    partial_train_labels = np.concatenate(\n",
    "        [train_labels[:i * num_val_samples],\n",
    "         train_labels[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    \n",
    "    sm = SMOTE()\n",
    "    train_set_res, train_labels_res = sm.fit_resample(partial_train_set.reshape(partial_train_set.shape[0], (128 * 128 * 1)), partial_train_labels)\n",
    "    train_set_res = train_set_res.reshape((train_set_res.shape[0], 128, 128, 1))\n",
    "    print(train_set_res.shape)\n",
    "    print(train_labels_res.shape)\n",
    "    \n",
    "    model = get_model()\n",
    "    history = model.fit(train_set_res, train_labels_res, \n",
    "                       batch_size=512, epochs=num_epochs, \n",
    "                       validation_data=(val_set, val_labels) , verbose=0)  #  # verbose=0 is used to train the model in silent mode\n",
    "    all_histories.append(history)\n",
    "    print('Processed fold #', i)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_histories[0].history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_accuracies = [ history.history['acc'] for history in all_histories ]\n",
    "all_val_accuracies = [ history.history['val_acc'] for history in all_histories ]\n",
    "all_losses = [ history.history['loss'] for history in all_histories ]\n",
    "all_val_losses = [ history.history['val_loss'] for history in all_histories ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_acc_history = [\n",
    "    np.mean([accs[i] for accs in all_accuracies]) for i in range(num_epochs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_val_acc_history = [\n",
    "    np.mean([val_accs[i] for val_accs in all_val_accuracies]) for i in range(num_epochs)\n",
    "]\n",
    "average_loss_history = [\n",
    "    np.mean([loss[i] for loss in all_losses]) for i in range(num_epochs)\n",
    "]\n",
    "average_val_loss_history = [\n",
    "    np.mean([val_loss[i] for val_loss in all_val_losses]) for i in range(num_epochs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(average_acc_history) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, average_acc_history, 'bo', label='Average training acc')\n",
    "plt.plot(epochs, average_val_acc_history, 'b', label='Average validation acc')\n",
    "plt.title('Average training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, average_loss_history, 'bo', label='Average training loss')\n",
    "plt.plot(epochs, average_val_loss_history, 'b', label='Average validation loss')\n",
    "plt.title('Average training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
